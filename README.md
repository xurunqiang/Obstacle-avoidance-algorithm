# 🚧 各类避障算法比较分析表

## 算法类别汇总表

| 算法类别       | 代表算法                  | 基本原理                                                                 | 优点                                     | 缺点                                     | 典型应用场景                 | 计算复杂度/实时性       |
|----------------|---------------------------|--------------------------------------------------------------------------|------------------------------------------|------------------------------------------|------------------------------|-------------------------|
| **几何类算法** | 人工势场法 (APF)          | 将目标设为吸引力，障碍设为排斥力，通过合力方向移动                         | 实现简单、计算快、实时性强               | 易陷局部最优、震荡问题严重               | 室内机器人、简单导航         | ★★★★★（快）            |
|                | 矢量场直方图 (VFH)        | 通过构建局部极坐标直方图，分析方向障碍密度                                 | 实时避障性能好、抗噪性强                 | 需要参数调优，路径不一定最优             | 移动机器人、自动驾驶         | ★★★★☆                  |
|                | 动态窗口法 (DWA)          | 在速度空间中搜索可行速度组合，优化速度与方向                               | 兼顾动力学约束、实时控制                 | 需精确模型，局部最优问题                 | 差速机器人、自主车           | ★★★★☆                  |
| **采样类算法** | RRT (快速随机树)          | 随机采样生成可行树，逐步逼近目标                                           | 能处理高维复杂空间                       | 路径不平滑、需后处理                     | 无人机、复杂环境探索         | ★★★☆☆                  |
|                | RRT*                      | RRT 改进版，增加路径优化过程                                               | 路径更优、收敛性好                       | 计算量较大，实时性低                     | 自动驾驶路径规划             | ★★☆☆☆                  |
|                | PRM (概率路标法)          | 随机采样节点并建立连通图                                                   | 适合静态全局规划                         | 不适合动态环境                           | 预知地图的机器人导航         | ★★☆☆☆                  |
| **搜索类算法** | A*                        | 基于启发式的最优路径搜索                                                   | 路径最优、易实现                         | 计算量随空间增大                         | 静态网格、地图导航           | ★★☆☆☆                  |
|                | D*                        | 动态 A* 改进，可增量更新路径                                               | 可适应动态环境                           | 实现复杂                                 | 自动驾驶、动态地图           | ★★★☆☆                  |
|                | Dijkstra                  | 经典最短路径算法                                                           | 全局最优、稳定                           | 无启发式，计算慢                         | 小规模路径规划               | ★☆☆☆☆                  |
| **智能/学习类** | 强化学习 (RL)             | 智能体通过奖励学习避障策略                                                 | 自适应、能应对未知环境                   | 训练耗时、难解释                         | 智能无人机、动态避障         | ★★★★☆                  |
|                | 深度强化学习 (DRL)        | 结合神经网络的强化学习                                                     | 可应对复杂感知输入                       | 高算力依赖，安全性待验证                 | 自动驾驶、仿真平台           | ★★★☆☆                  |
|                | 模糊控制 / 神经网络控制   | 通过经验规则或学习拟合控制策略                                             | 无需精确模型、鲁棒性好                   | 精度有限、需调参                         | 服务机器人、地面移动平台     | ★★★★☆                  |
| **融合类算法** | VFH + A*、DWA + RL 等     | 将局部避障与全局规划结合                                                   | 平衡最优与实时性                         | 系统复杂度高                             | 智能车、仓储机器人           | ★★★★☆                  |


## 应用场景推荐

| 应用场景               | 推荐算法                | 推荐理由                                     |
|------------------------|-------------------------|----------------------------------------------|
| 室内移动机器人         | DWA、VFH、APF           | 环境变化快、需高实时性                       |
| 复杂未知环境探索       | RRT*、RL                | 高维空间、需自适应能力                       |
| 自动驾驶/大场景路径    | A* + DWA 或 D* Lite     | 全局+局部融合最稳定                         |
| 无人机三维避障         | RRT*、DRL               | 可处理连续高维状态空间                       |
| 群体机器人协作         | RL、多智能体强化学习 (MARL) | 需分布式决策能力                             |

